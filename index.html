<!DOCTYPE html>
<html>
<head>
  <meta charset="UTF-8">
  <title>Conversations Are Long, Emotions Are Subtle</title>
  <!-- external -->
  <link rel="stylesheet" href="style.css">
</head>

<body>

  <!-- HERO -->
  <header class="hero">
    <div class="hero-inner">
      <div class="hero-text">
        <h1 class="hero-title">
          Conversations Are Long, Emotions Are Subtle
        </h1>
        <h2 class="hero-subtitle">
          How Memory Networks, Transformer-XL, and Emotion Anchors Reshape Conversational Emotion Recognition
        </h2>
        <div class="hero-meta">
          DS-GA 1011 · Fall 2025 · Ellie Wang, Georgios Ioannou, Qiya Huang, Ruokai Gu, Ziyu Qi
        </div>
      </div>
      <div class="hero-image">
        <img src="images/hybrid-flowchart.svg" alt="Hybrid model flowchart" class="hero-flow">
      </div>
    </div>
  </header>

  <!--body -->
  <div class="page">
    <main class="content">
      <h2>Why conversational emotion is hard</h2>
      <p>
        Single-utterance emotion classification is already challenging, but conversational emotion recognition raises the difficulty in several important ways. Emotions in dialogue rarely appear in clean, self-contained sentences. A single line like <i>“It’s fine, whatever”</i> might signal annoyance, resignation, or genuine agreement—its meaning depends almost entirely on the surrounding context and the speaker’s intent.
      </p>      
      <p>
        More importantly, emotions in conversation unfold over time. They accumulate across turns, shift gradually, and often blur the boundaries between categories such as frustration, annoyance, and sadness. Yet many existing systems still analyze each utterance in isolation, overlooking the long-range dependencies and speaker-specific patterns that shape how emotions evolve within a dialogue.
      </p>      
      <p>
        This blog explores whether modern neural architectures can better follow these emotional trajectories. Rather than proposing a new architecture from scratch, we revisit three influential ideas in conversational emotion recognition—speaker-specific memory networks (CMN), long-context transformers (Transformer-XL), and emotion-anchored contrastive learning (EACL). Each addresses a different limitation in how models interpret emotional dynamics.
      </p>
      <p>
        We reproduce all three models on the IEMOCAP benchmark and study where they excel and where they fall short, centered around a guiding question:
        <strong>Can long-range context modeling and structured emotional representations be combined into a single, more interpretable system?</strong>
      </p>
      <p>
        The sections that follow trace this investigation—from CMN’s limited short-term memory, to Transformer-XL’s ability to capture emotional buildup across long conversations, to EACL’s reshaping of the embedding space using learned emotion anchors. Along the way, we compare their behaviors side-by-side, highlight a few surprising patterns, and outline a hybrid approach that integrates their most promising ideas.
      </p>


      <h2 id="problem">2. Problem Setup: Conversational Emotion Recognition</h2>
      <p>
        We focus on utterance-level emotion recognition in multi-turn dialogues.
        Each conversation is a sequence of utterances produced by different speakers, and the goal is
        to predict an emotion label (e.g., <i>happy</i>, <i>sad</i>, <i>angry</i>) for every utterance.
        Our main benchmark is the IEMOCAP dataset, a widely used corpus of dyadic conversations with
        speaker-annotated emotion labels.
      </p>

      <h2 id="cmn">3. Conversational Memory Networks (CMN, 2018)</h2>
      <p>
        CMN introduces speaker-specific memory modules that store recent utterances for each participant.
        Multimodal features from text, audio, and visual channels are fused into a single vector and written
        into the corresponding speaker memory. An attention mechanism then reads from these memories to
        produce a context-aware representation for the current utterance, which is fed into a classifier.
        CMN captures short-term emotional dependencies and speaker identity, but its fixed-size memory window
        limits its ability to model long conversations and gradual emotional shifts.
      </p>

      <h2 id="txl">4. Transformer-XL for Long-Context Modeling</h2>
<p>
Consider a scenario where a speaker begins a conversation calmly discussing work stress, then becomes increasingly frustrated over several turns, and finally expresses anger when the topic shifts back to the initial stressor. CMN's short window might catch the immediate trigger, but it misses the <em>emotional buildup</em> that spans much earlier in the dialogue. This is where <strong>Transformer-XL</strong> becomes valuable.
</p>

<h3>The Core Problem: Context Fragmentation</h3>

<p>
Standard transformers operate on fixed-length segments. When a conversation exceeds this length, it must be split into multiple chunks. This creates what the original Transformer-XL paper calls <strong>context fragmentation</strong>—the loss of continuity at segment boundaries. For emotion recognition, this is particularly problematic because <span class="highlight">emotional context doesn't respect arbitrary segment divisions</span>.
</p>

<h3>Transformer-XL's Solution: Segment-Level Recurrence</h3>

<p>
Transformer-XL introduces <strong>segment-level recurrence</strong> to address fragmentation. Instead of discarding hidden states after processing a segment, the model <em>caches</em> them and reuses them when encoding the next segment. Concretely:
</p>

<ul>
    <li>Segment 1 (utterances 1-4) is encoded, producing hidden states <code>H₁</code>.</li>
    <li>These states are cached in memory.</li>
    <li>When encoding Segment 2 (utterances 5-8), the model attends not only to the current segment but also to the cached <code>H₁</code>.</li>
    <li>This process repeats, creating a <em>recurrent connection</em> across segments while keeping backpropagation local to each segment.</li>
</ul>

<p>
The result is that <span class="highlight">the effective context length grows linearly with the number of layers and segments</span>. The original Transformer-XL paper reports dependencies 80% longer than RNNs and 450% longer than vanilla transformers. For conversational emotion recognition, this means the model can now look back 10, 15, or even 20 turns to understand how emotions have evolved.
</p>

<img src="images/txl.png" alt="Architecture comparison: CMN Baseline vs CMN + Transformer-XL" class="architecture-img">
<p class="caption">
    <strong>Figure 1:</strong> Architectural comparison between CMN baseline and CMN enhanced with Transformer-XL. 
</p>

<h3>Relative Positional Encodings</h3>
<p>
A subtle but critical challenge arises when reusing cached states: <em>positional information becomes ambiguous</em>. In standard transformers, each token has an absolute position (e.g., position 3 in a sequence). But when Segment 2 reuses cached states from Segment 1, those cached states still "think" they're at positions 1–4, even though they're now being attended to from positions 5–8. This creates temporal confusion.
</p>

<p>
Transformer-XL resolves this by replacing <strong>absolute positional encodings</strong> with <strong>relative positional encodings</strong>. Relative distances remain consistent regardless of which segment is being processed, allowing cached states to integrate smoothly into new contexts without losing their temporal coherence.
</p>

<h3>Integration with CMN</h3>
<p>
Rather than replacing CMN entirely, we <em>integrate</em> Transformer-XL into its architecture. This allows us to:
</p>

<ul>
    <li>Track individual speaker states separately (maintaining CMN's design philosophy)</li>
    <li>Extend each speaker's memory across longer conversational history (adding Transformer-XL's recurrence)</li>
    <li>Apply relative positional encodings to handle temporal coherence</li>
</ul>

<p>
The result is a model that combines <strong>speaker identity tracking</strong> with <strong>long-range dependency modeling</strong>—two complementary capabilities that neither CMN nor Transformer-XL alone fully addresses.
</p>

<h3>Impact</h3>
<p>
Transformer-XL shows the largest improvements on <em>long conversations</em> where emotions shift gradually across many turns. On shorter dialogues (≤5 turns), the benefit of extended context is modest, since CMN's fixed window already covers most of the conversation. However, for dialogues with longer turns—where emotional buildup, callbacks to earlier topics, and speaker interaction patterns span the entire conversation—Transformer-XL significantly outperform the CMN baseline.
</p>

      <h2 id="eacl">5. Emotion-Anchored Contrastive Learning (EACL, 2024)</h2>
      <p>
        Even with a strong encoder, many emotion categories remain confusable in representation space.
        EACL proposes to learn a set of trainable <i>emotion anchors</i>, one prototype vector per class.
        During training, each utterance embedding is pulled toward its corresponding anchor and pushed away
        from others via a contrastive loss, while an additional anchor-angle loss keeps anchors themselves
        well separated. This reshapes the embedding space so that similar emotions remain close but class
        boundaries become clearer.
      </p>

      <!-- NEW ANALYSIS: error structure under EACL -->
      <figure class="figure">
        <img src="images/EACL-heatmap.png"
             alt="Error heatmap for EACL on IEMOCAP"
             class="figure-image">
        <figcaption class="figure-caption">
          <strong>Figure 1. How EACL changes the error structure.</strong>
          We plot a heatmap of prediction errors on IEMOCAP to see which emotion pairs are still
          confused under EACL. The main patterns are:
          <ul>
            <li><b>Excited–Happy</b> and <b>Frustrated–Angry</b> show noticeably fewer cross-class errors
                compared to the baseline, indicating that anchor-based training helps separate these
                subtle pairs.</li>
            <li><b>Neutral–Sad</b> remains a major source of confusion, suggesting that conversational
                ambiguity and similar lexical cues limit how cleanly these two classes can be separated.</li>
          </ul>
          This error-level view is not reported in the original EACL paper and highlights how anchors
          behave specifically in a conversational setting.
        </figcaption>
      </figure>

      <!-- NEW ANALYSIS: geometry of emotion anchors -->
      <figure class="figure">
        <img src="images/eacl-anchor.png"
             alt="Emotion anchors and utterance clusters in embedding space"
             class="figure-image figure-image-small">
        <figcaption class="figure-caption">
          <strong>Figure 2. Emotion anchors act as attractors in embedding space.</strong>
          We visualize the learned anchors together with utterance embeddings. After training:
          <ul>
            <li>Utterances with the same label form tighter, more compact clusters around their
                corresponding anchors.</li>
            <li>Anchors themselves move to more “central” positions inside each cluster, acting as
                attractors that stabilize emotion-specific regions.</li>
            <li>Border regions between <b>excited–happy</b> and <b>frustrated–angry</b> become sharper,
                while the overlap between <b>neutral</b> and <b>sad</b> remains visible.</li>
          </ul>
        </figcaption>
      </figure>

      <p>
        Taken together, these analyses show that EACL does more than increase accuracy: it tightens the
        geometry of the representation space and makes several confusable emotions easier to tell apart,
        while revealing intrinsic limits for ambiguous classes like <i>neutral</i> vs. <i>sad</i>.
        This provides an interpretable lens on how contrastive anchors reshape conversational emotion
        representations, which we later combine with long-context modeling in our hybrid architecture.
      </p>

      <h2 id="hybrid">6. Hybrid Architecture: Long Context + Emotion Anchors</h2>
      <p>
        Our main insight is that long-context modeling and emotion-anchored representation learning are
        complementary. We therefore extend the CMN baseline by replacing its utterance encoder with a
        Transformer-XL encoder and attaching an EACL-style contrastive head on top of the encoder outputs.
        The overall loss combines cross-entropy for label prediction, a contrastive term for utterance–anchor
        alignment, and an anchor-angle term that encourages diverse emotion prototypes. This hybrid design
        is intended to promote both context stability across long conversations and clearer emotional
        boundaries in the embedding space.
      </p>

      <h2 id="experiments">7. Experiments and Comparative Analysis</h2>
      <p>
        In our study, we reproduce CMN, Transformer-XL, and EACL on the IEMOCAP dataset and compare their
        performance under a unified evaluation setup. We also analyze confusion matrices and embedding
        visualizations to understand how each architecture handles similar emotion categories such as
        <i>angry</i> vs. <i>frustrated</i>. Finally, we outline an evaluation protocol for the proposed
        hybrid model, including metrics, cross-dataset tests, and speaker-independent splits.
      </p>

      <h2 id="conclusion">8. Discussion and Conclusion</h2>
      <p>
        Conversational emotion recognition challenges models to reason over long context, speaker identity,
        and subtle differences between related emotions. Memory networks, recurrent transformers, and
        contrastive emotion anchors each address a different part of this problem. By viewing them together
        and proposing a hybrid architecture, we highlight how future work can move beyond single-model
        improvements toward more integrated and interpretable approaches to emotion in dialogue.
      </p>
    </main>

    <aside class="sidebar">
      <div class="sidebar-title">QUICK LINKS</div>
      <ul class="sidebar-link-list">
        <li><a href="https://github.com/GeorgiosIoannouCoder/ecem-csa" target="_blank">GitHub Repo</a></li>
        <li><a href="POSTER_PDF_LINK_HERE" target="_blank">Poster (PDF)</a></li>
        <li><a href="#hybrid">Hybrid Model</a></li>
        <li><a href="#experiments">Experiments</a></li>
      </ul>

      <div class="sidebar-title">SHARE</div>
      <p>
        Copy and share this link:<br>
        <code>https://georgiosioannou.com/ecem-csa/</code>
      </p>
    </aside>
  </div>

</body>
</html>

